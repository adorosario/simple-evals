# HTML Report Catalog - Complete Inventory

## Overview
This document catalogs ALL HTML report types generated by the SimpleEvals system.
Each report type must use the unified brand kit for consistency.

---

## 1. Core Dashboard & Quality Reports (HIGH PRIORITY)

### 1.1 Main Dashboard
- **Files**: `main_report.html`, `index.html` (3 instances each)
- **Generator**: `scripts/generate_main_dashboard.py`
- **Status**: ✅ USES BRAND KIT (`report_generators.py`)
- **Description**: Central hub linking to all sub-reports

### 1.2 Quality Benchmark Reports
- **Files**: `quality_benchmark_report_*.html` (40+ instances)
- **Generator**: `scripts/confidence_threshold_benchmark.py` → `scripts/report_generators.py`
- **Status**: ✅ USES BRAND KIT (`generate_quality_benchmark_report_v2`)
- **Description**: Provider performance leaderboard with penalty-aware scoring

### 1.3 Statistical Analysis
- **Files**: `statistical_analysis.html`, `statistical_analysis_run_*.html` (2+ instances)
- **Generator**: `scripts/academic_statistical_analysis.py`
- **Status**: ⚠️ PARTIAL - May have inline HTML generation
- **Description**: Wilson score confidence intervals, significance testing

---

## 2. Forensic Analysis Reports (HIGH PRIORITY - 270+ files)

### 2.1 Forensic Dashboard
- **Files**: `forensic_dashboard.html` (10 instances)
- **Generator**: `scripts/generate_forensic_reports.py` → `generate_forensic_dashboard()`
- **Status**: ❌ USES INLINE STYLES (lines 219-230)
- **Description**: Overview of all penalty cases with domain breakdown

### 2.2 Individual Question Forensics
- **Files**: `forensic_question_simpleqa_*.html` (262 instances)
- **Generator**: `scripts/generate_forensic_reports.py` → `generate_individual_question_report()`
- **Status**: ❌ USES INLINE STYLES (same template)
- **Description**: Deep-dive analysis for each failed question

### 2.3 Engineering Reports
- **Files**: `customgpt_engineering_report.html`
- **Generator**: `scripts/generate_forensic_reports.py` → `convert_engineering_report_to_html()`
- **Status**: ❌ USES INLINE STYLES (same template)
- **Description**: Markdown-to-HTML converted engineering post-mortem

---

## 3. Specialized Analysis Reports (MEDIUM PRIORITY)

### 3.1 Detailed Failure Analysis
- **Files**:
  - `customgpt_detailed_analysis.html`
  - `customgpt_detailed_failure_analysis.html`
  - `customgpt_detailed_failure_analysis_with_judge_reasoning.html`
  - `customgpt_detailed_audit_*.html`
- **Generator**: `scripts/generate_universal_forensics.py` (likely)
- **Status**: ⚠️ UNKNOWN - Need to check generator
- **Description**: In-depth forensic analysis with judge reasoning

### 3.2 Flex Tier Comparisons
- **Files**: `flex_tier_comparison_*.html` (4 instances)
- **Generator**: `scripts/flex_tier_comparison.py`
- **Status**: ⚠️ UNKNOWN - Need to check if exists
- **Description**: GPT-5 Flex vs Standard tier comparison

### 3.3 Legacy Comparison Reports
- **Files**: `three_way_rag_comparison_*.html`
- **Generator**: Unknown (legacy?)
- **Status**: ⚠️ UNKNOWN
- **Description**: Three-way RAG provider comparison

---

## 4. Legacy Reports (LOW PRIORITY - May be deprecated)

### 4.1 Confidence Threshold Reports (Legacy)
- **Files**: `confidence_threshold_report_*.html` (30 instances from Sept 2025)
- **Generator**: Old version of `scripts/confidence_threshold_benchmark.py`
- **Status**: ❌ LIKELY DEPRECATED - Replaced by quality_benchmark_report
- **Description**: Old confidence threshold analysis (pre-brand kit)

### 4.2 Multi-Provider Leaderboards (Legacy)
- **Files**: `multi_provider_leaderboard_*.html` (8 instances from Sept 2025)
- **Generator**: `scripts/multi_provider_benchmark.py` (v1.x)
- **Status**: ⚠️ LEGACY - May still be used
- **Description**: Legacy multi-provider comparison

---

## 5. Individual Eval Reports (LOW PRIORITY - Per-eval dashboards)

- **Files**:
  - `simpleqa_customgpt.html`
  - `mmlu_customgpt.html`
  - `mgsm_customgpt.html`
  - `math_customgpt.html`
  - `gpqa_customgpt.html`
- **Generator**: Individual eval modules (`*_eval.py`)
- **Status**: ⚠️ UNKNOWN - Likely have their own HTML generation
- **Description**: Per-evaluation-type detailed reports

---

## 6. Blog Posts / Narrative Reports (LOW PRIORITY - One-offs)

- **Files**:
  - `why_rags_hallucinate_blog_post.html`
  - `viral_blog_post_interactive.html`
  - `narrative_blog_post.html`
  - `adaptive_blog_post.html`
  - `beautiful_viral_blog_post.html`
- **Generator**:
  - `scripts/generate_html_blog_post.py`
  - `scripts/create_narrative_blog_post.py`
  - `scripts/create_beautiful_html_blog.py`
  - `scripts/generate_adaptive_blog_post.py`
- **Status**: ❌ LIKELY USE CUSTOM INLINE STYLES
- **Description**: Marketing/narrative content, different from analytical reports

---

## Brand Kit Migration Priority

### Phase 1: Core System (IMMEDIATE)
1. ✅ Main Dashboard (`generate_main_dashboard.py`) - ALREADY DONE
2. ✅ Quality Benchmark (`report_generators.py`) - ALREADY DONE
3. ❌ **Forensic Reports** (`generate_forensic_reports.py`) - IN PROGRESS
   - Forensic dashboard
   - Individual question reports
   - Engineering report conversion

### Phase 2: Analysis Reports (HIGH PRIORITY)
4. ⚠️ Statistical Analysis (`academic_statistical_analysis.py`)
5. ⚠️ Detailed Analysis (`generate_universal_forensics.py`)
6. ⚠️ Flex Tier Comparison (`flex_tier_comparison.py`)

### Phase 3: Legacy/Other (LOWER PRIORITY)
7. Multi-provider leaderboards (if still used)
8. Individual eval dashboards
9. Blog posts (may keep custom styling)

---

## Internal Linking Requirements

All reports must link to:
- **Home**: `index.html` or `main_report.html`
- **Quality Benchmark**: `quality_benchmark_report_*.html`
- **Statistical Analysis**: `statistical_analysis_run_*.html`
- **Forensics**:
  - Dashboard: `forensic_dashboard.html`
  - Individual: `forensic_question_*.html`

Navigation must be consistent using `get_navigation_bar()` from brand kit.

---

## Files Requiring Updates

### Immediate (Phase 1)
- `scripts/generate_forensic_reports.py` (CRITICAL - 270+ HTML files)

### High Priority (Phase 2)
- `scripts/academic_statistical_analysis.py`
- `scripts/generate_universal_forensics.py`
- `scripts/flex_tier_comparison.py` (if exists)

### Audit Needed
- Individual `*_eval.py` modules for HTML generation
- Legacy script cleanup

---

## Success Criteria

✅ All HTML files use brand kit's `get_html_head()`
✅ All HTML files use brand kit's `get_navigation_bar()`
✅ All HTML files use brand kit's `get_page_header()`
✅ All links between reports work correctly
✅ All styling is consistent (no inline styles except brand kit)
✅ All animations and interactions are smooth and consistent
✅ Mobile-responsive on all reports
✅ WCAG AA accessibility compliance

---

Generated: 2025-10-25
Last Updated: 2025-10-25
