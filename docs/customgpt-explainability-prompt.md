ok - so here is the deal: CustomGPT.ai now has new explainability features enabled in their API -- these provide excellent information around explainability of the response, and breakdown of the claims along with trust scores. 

I think these can be used to investigate why CustomGPT.ai failed on a query ..  (Ninja move: it could potentially even be used for improving the quality for async responses for regulated industries, but we will do that later). 

For now, I need you to run post-mortem investigations on all queries that CustomGPT.ai failed on and create a report that engineering can review and investigate. That is the goal at hand -- to understand what the current fragilities of the CustomGPT.ai platform are (even though it is the best) -- and improve the quality even further. 

So lets ultrathink about this and create a customgpt-explainability-goal.md -- and then we will figure out how to reach 85% quality metric for CustomGPT.ai. 

PS: You can look into /home/adorosario/quick-and-dirty/customgpt-manus-like-agent-poc for a framework on how to create the customgpt-explainability-goal.md and customgpt-explainability-todo.md .. also: please see: customgpt-explainability.md and the explainability-?.png images as needed. 